main:
  params: [args]
  steps:
    - init:
        assign:
        - project: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
        - location: "us-central1"
    - run_ads_workflow:
        call: runAdsQueries
        args:
          project: ${project}
          location: ${location}
          function_name: ${args.cloud_function}
          gcs_bucket: ${args.gcs_bucket}
          queries_path: ${args.ads_queries_path}
          dataset: ${args.dataset}
          cid: ${args.cid}
          macros: ${args.ads_macro}
          ads_config_path: ${args.ads_config_path}
    - run_bq_workflow:
        call: runBigQueryQueries
        args:
          project: ${project}
          location: ${location}
          function_name: ${args.cloud_function + "-bq"}
          gcs_bucket: ${args.gcs_bucket}
          queries_path: ${args.bq_queries_path}
          macros: ${args.bq_macro}
          sqlParams: ${args.bq_sql}

runAdsQueries:
  params: [project, location, function_name, gcs_bucket, queries_path, dataset, cid, macros, ads_config_path]
  # NOTE: currently it's assumed that CF's project is the same as project for BQ datasets
  steps:
    # get CF function URL (specially usefull for v2 CF)
    - get_function:
        call: googleapis.cloudfunctions.v1.projects.locations.functions.get
        args:
          name: ${"projects/" + project + "/locations/" + location + "/functions/" + function_name}
        result: function
    - log_functions_metadata:
        call: sys.log
        args:
          data: ${function}
    # fetch script from GCS
    - get_ads_scripts_from_gcs:
        call: googleapis.storage.v1.objects.list
        args:
          bucket: ${gcs_bucket}
          prefix: ${queries_path}
        result: scripts
    - log_ads_scripts:
        call: sys.log
        args:
          data: ${scripts.items}
          severity: "INFO"
    - runAdsQueries:
        parallel:
          shared: [scripts]
          for:
            value: script_item
            in: ${scripts.items}
            steps:
              - call_gaarf_cf:
                  call: http.post
                  args:
                    url: ${function.httpsTrigger.url}
                    query:
                      script_path: ${"gs://" + gcs_bucket + "/" + script_item.name}
                      bq_project_id: ${project}
                      bq_dataset: ${dataset}
                      customer_id: ${cid}
                      ads_config_path: ${ads_config_path}
                    body:
                      macro: ${macros}
                    auth:
                      type: OIDC
                      audience: ${function.httpsTrigger.url}
                  result: script_results
              - log_script_result:
                  call: sys.log
                  args:
                    data: ${script_results.body}
                    severity: "INFO"

runBigQueryQueries:
  params: [project, location, function_name, gcs_bucket, queries_path, macros, sqlParams]

  steps:
    - get_bq_scripts_from_gcs:
        call: googleapis.storage.v1.objects.list
        args:
          bucket: ${gcs_bucket}
          prefix: ${queries_path}
        result: bq_scripts
    - log_bq_scripts:
        call: sys.log
        args:
          data: ${bq_scripts.items}
          severity: "INFO"
    # check scripts were found on GCS
#    - check_scripts:
#        switch:
#          - condition: ${bq_scripts["items"] and len(bq_scripts.items) > 0}
#            next: get_function_bq
#        next: end
    - get_function_bq:
        call: googleapis.cloudfunctions.v1.projects.locations.functions.get
        args:
          name: ${"projects/" + project + "/locations/" + location + "/functions/" + function_name}
        result: function_bq
    - runBqQueries:
        parallel:
          shared: [bq_scripts]
          for:
            value: bq_script_item
            in: ${bq_scripts.items}
            steps:
              - call_gaarf_bq_cf:
                  call: http.post
                  args:
                    url: ${function_bq.httpsTrigger.url}
                    query:
                      script_path: ${"gs://" + gcs_bucket + "/" + bq_script_item.name}
                      project_id: ${project}
                    body:
                      macro: ${macros}
                      sql: ${sqlParams}
                    auth:
                      type: OIDC
                      audience: ${function_bq.httpsTrigger.url}
                  result: script_results
              - log_script_bq_result:
                  call: sys.log
                  args:
                    data: ${script_results.body}
                    severity: "INFO"
# TODO:
# * safely ignore the absence of scripts on GCS